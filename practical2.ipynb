{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practical 2: \n",
    "<p>Oxford CS - Deep NLP 2017<br>\n",
    "https://www.cs.ox.ac.uk/teaching/courses/2016-2017/dl/</p>\n",
    "<p>[Yannis Assael, Brendan Shillingford, Chris Dyer]</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from random import shuffle\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"http://bokeh.pydata.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"449c76af-2fdf-4480-858b-aec2df2315fd\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(global) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof (window._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n",
       "    window._bokeh_onload_callbacks = [];\n",
       "    window._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "\n",
       "  \n",
       "  if (typeof (window._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    window._bokeh_timeout = Date.now() + 5000;\n",
       "    window._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    if (window.Bokeh !== undefined) {\n",
       "      document.getElementById(\"449c76af-2fdf-4480-858b-aec2df2315fd\").textContent = \"BokehJS successfully loaded.\";\n",
       "    } else if (Date.now() < window._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function run_callbacks() {\n",
       "    window._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n",
       "    delete window._bokeh_onload_callbacks\n",
       "    console.info(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(js_urls, callback) {\n",
       "    window._bokeh_onload_callbacks.push(callback);\n",
       "    if (window._bokeh_is_loading > 0) {\n",
       "      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    window._bokeh_is_loading = js_urls.length;\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var s = document.createElement('script');\n",
       "      s.src = url;\n",
       "      s.async = false;\n",
       "      s.onreadystatechange = s.onload = function() {\n",
       "        window._bokeh_is_loading--;\n",
       "        if (window._bokeh_is_loading === 0) {\n",
       "          console.log(\"Bokeh: all BokehJS libraries loaded\");\n",
       "          run_callbacks()\n",
       "        }\n",
       "      };\n",
       "      s.onerror = function() {\n",
       "        console.warn(\"failed to load library \" + url);\n",
       "      };\n",
       "      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "    }\n",
       "  };var element = document.getElementById(\"449c76af-2fdf-4480-858b-aec2df2315fd\");\n",
       "  if (element == null) {\n",
       "    console.log(\"Bokeh: ERROR: autoload.js configured with elementid '449c76af-2fdf-4480-858b-aec2df2315fd' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.4.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.4.min.js\"];\n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      \n",
       "      document.getElementById(\"449c76af-2fdf-4480-858b-aec2df2315fd\").textContent = \"BokehJS is loading...\";\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-0.12.4.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.4.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.4.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.4.min.css\");\n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if ((window.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i](window.Bokeh);\n",
       "      }if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < window._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!window._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      window._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"449c76af-2fdf-4480-858b-aec2df2315fd\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (window._bokeh_is_loading === 0) {\n",
       "    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(js_urls, function() {\n",
       "      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(this));"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from bokeh.models import ColumnDataSource, LabelSet\n",
    "from bokeh.plotting import figure, show, output_file\n",
    "from bokeh.io import output_notebook\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 0: Downloading and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import zipfile\n",
    "import lxml.etree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Download the dataset if it's not already there: this may take a minute as it is 75MB\n",
    "if not os.path.isfile('ted_en-20160408.zip'):\n",
    "    urllib.request.urlretrieve(\"https://wit3.fbk.eu/get.php?path=XML_releases/xml/ted_en-20160408.zip&filename=ted_en-20160408.zip\", filename=\"ted_en-20160408.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For now, we're only interested in the subtitle text, so let's extract that from the XML:\n",
    "with zipfile.ZipFile('ted_en-20160408.zip', 'r') as z:\n",
    "    doc = lxml.etree.parse(z.open('ted_en-20160408.xml', 'r'))\n",
    "input_text = '\\n'.join(doc.xpath('//content/text()'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "root = doc.getroot()\n",
    "\n",
    "talks = list()\n",
    "\n",
    "for item in root:\n",
    "    id = int(item.attrib.get('id'))\n",
    "    #keywords\n",
    "    keywords = item[0][5].text    \n",
    "    talks.append( (item[1].text, keywords) )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The XML is traversed, and for each talk we obtain the text of the talk, as well as associated keywords. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Here are two reasons companies fail: they only do more of the same, or they only do what\\'s new.\\nTo me the real, real solution to quality growth is figuring out the balance between two activities: exploration and exploitation. Both are necessary, but it can be too much of a good thing.\\nConsider Facit. I\\'m actually old enough to remember them. Facit was a fantastic company. They were born deep in the Swedish forest, and they made the best mechanical calculators in the world. Everybody used them. And what did Facit do when the electronic calculator came along? They continued doing exactly the same. In six months, they went from maximum revenue ... and they were gone. Gone.\\nTo me, the irony about the Facit story is hearing about the Facit engineers, who had bought cheap, small electronic calculators in Japan that they used to double-check their calculators.\\n(Laughter)\\nFacit did too much exploitation. But exploration can go wild, too.\\nA few years back, I worked closely alongside a European biotech company. Let\\'s call them OncoSearch. The company was brilliant. They had applications that promised to diagnose, even cure, certain forms of blood cancer. Every day was about creating something new. They were extremely innovative, and the mantra was, \"When we only get it right,\" or even, \"We want it perfect.\" The sad thing is, before they became perfect -- even good enough -- they became obsolete. OncoSearch did too much exploration.\\nI first heard about exploration and exploitation about 15 years ago, when I worked as a visiting scholar at Stanford University. The founder of the idea is Jim March. And to me the power of the idea is its practicality.\\nExploration. Exploration is about coming up with what\\'s new. It\\'s about search, it\\'s about discovery, it\\'s about new products, it\\'s about new innovations. It\\'s about changing our frontiers. Our heroes are people who have done exploration: Madame Curie, Picasso, Neil Armstrong, Sir Edmund Hillary, etc. I come from Norway; all our heroes are explorers, and they deserve to be. We all know that exploration is risky. We don\\'t know the answers, we don\\'t know if we\\'re going to find them, and we know that the risks are high.\\nExploitation is the opposite. Exploitation is taking the knowledge we have and making good, better. Exploitation is about making our trains run on time. It\\'s about making good products faster and cheaper. Exploitation is not risky -- in the short term. But if we only exploit, it\\'s very risky in the long term. And I think we all have memories of the famous pop groups who keep singing the same songs again and again, until they become obsolete or even pathetic. That\\'s the risk of exploitation.\\nSo if we take a long-term perspective, we explore. If we take a short-term perspective, we exploit. Small children, they explore all day. All day it\\'s about exploration. As we grow older, we explore less because we have more knowledge to exploit on. The same goes for companies. Companies become, by nature, less innovative as they become more competent.\\nAnd this is, of course, a big worry to CEOs. And I hear very often questions phrased in different ways. For example, \"How can I both effectively run and reinvent my company?\" Or, \"How can I make sure that our company changes before we become obsolete or are hit by a crisis?\" So, doing one well is difficult. Doing both well as the same time is art -- pushing both exploration and exploitation.\\nSo one thing we\\'ve found is only about two percent of companies are able to effectively explore and exploit at the same time, in parallel. But when they do, the payoffs are huge. So we have lots of great examples. We have NestlÃ© creating Nespresso, we have Lego going into animated films, Toyota creating the hybrids, Unilever pushing into sustainability -- there are lots of examples, and the benefits are huge.\\nWhy is balancing so difficult? I think it\\'s difficult because there are so many traps that keep us where we are. So I\\'ll talk about two, but there are many.\\nSo let\\'s talk about the perpetual search trap. We discover something, but we don\\'t have the patience or the persistence to get at it and make it work. So instead of staying with it, we create something new. But the same goes for that, then we\\'re in the vicious circle of actually coming up with ideas but being frustrated. OncoSearch was a good example. A famous example is, of course, Xerox. But we don\\'t only see this in companies. We see this in the public sector as well. We all know that any kind of effective reform of education, research, health care, even defense, takes 10, 15, maybe 20 years to work. But still, we change much more often. We really don\\'t give them the chance.\\nAnother trap is the success trap. Facit fell into the success trap. They literally held the future in their hands, but they couldn\\'t see it. They were simply so good at making what they loved doing, that they wouldn\\'t change. We are like that, too. When we know something well, it\\'s difficult to change. Bill Gates has said: \"Success is a lousy teacher. It seduces us into thinking we cannot fail.\" That\\'s the challenge with success.\\nSo I think there are some lessons, and I think they apply to us. And they apply to our companies. The first lesson is: get ahead of the crisis. And any company that\\'s able to innovate is actually able to also buy an insurance in the future. Netflix -- they could so easily have been content with earlier generations of distribution, but they always -- and I think they will always -- keep pushing for the next battle. I see other companies that say, \"I\\'ll win the next innovation cycle, whatever it takes.\"\\nSecond one: think in multiple time scales. I\\'ll share a chart with you, and I think it\\'s a wonderful one. Any company we look at, taking a one-year perspective and looking at the valuation of the company, innovation typically accounts for only about 30 percent. So when we think one year, innovation isn\\'t really that important. Move ahead, take a 10-year perspective on the same company -- suddenly, innovation and ability to renew account for 70 percent. But companies can\\'t choose. They need to fund the journey and lead the long term.\\nThird: invite talent. I don\\'t think it\\'s possible for any of us to be able to balance exploration and exploitation by ourselves. I think it\\'s a team sport. I think we need to allow challenging. I think the mark of a great company is being open to be challenged, and the mark of a good corporate board is to constructively challenge. I think that\\'s also what good parenting is about.\\nLast one: be skeptical of success. Maybe it\\'s useful to think back at the old triumph marches in Rome, when the generals, after a big victory, were given their celebration. Riding into Rome on the carriage, they always had a companion whispering in their ear, \"Remember, you\\'re only human.\"\\nSo I hope I made the point: balancing exploration and exploitation has a huge payoff. But it\\'s difficult, and we need to be conscious.\\nI want to just point out two questions that I think are useful. First question is, looking at your own company: In which areas do you see that the company is at the risk of falling into success traps, of just going on autopilot? And what can you do to challenge?\\nSecond question is: When did I explore something new last, and what kind of effect did it have on me? Is that something I should do more of? In my case, yes.\\nSo let me leave you with this. Whether you\\'re an explorer by nature or whether you tend to exploit what you already know, don\\'t forget: the beauty is in the balance.\\nThank you.\\n(Applause)', 'talks, business, creativity, curiosity, goal-setting, innovation, motivation, potential, success, work')]\n",
      "2085 talks parsed.\n"
     ]
    }
   ],
   "source": [
    "print (talks[:1])\n",
    "\n",
    "print(len(talks) , \"talks parsed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This then needs to be reformatted, so that only the relevant keywords are included, and the text content is tokenised in the same manner as the first practical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_label(keywords):\n",
    "    labels = [x.strip() for x in keywords.split(',')]\n",
    "    \n",
    "    label1 = \"o\"\n",
    "    label2 = \"o\"\n",
    "    label3 = \"o\"\n",
    "    \n",
    "    if \"technology\" in labels:\n",
    "        label1 = \"T\"\n",
    "    if \"entertainment\" in labels:\n",
    "        label2 = \"E\"\n",
    "    if \"design\" in labels:\n",
    "        label3 = \"D\"\n",
    "        \n",
    "    return label1 + label2 + label3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "processed_talks = list()\n",
    "\n",
    "for (talk, keywords) in talks:\n",
    "    input_text_noparens = re.sub(r'\\([^)]*\\)', '', talk)\n",
    "\n",
    "    sentences_strings_ted = []\n",
    "\n",
    "    for line in input_text_noparens.split('\\n'):\n",
    "        m = re.match(r'^(?:(?P<precolon>[^:]{,20}):)?(?P<postcolon>.*)$', line)\n",
    "        sentences_strings_ted.extend(sent for sent in m.groupdict()['postcolon'].split('.') if sent)\n",
    "\n",
    "        sentences_ted = []\n",
    "    for sent_str in sentences_strings_ted:\n",
    "        tokens = re.sub(r\"[^a-z0-9]+\", \" \", sent_str.lower()).split()\n",
    "        sentences_ted.append(tokens)\n",
    "        \n",
    "    #Process keywords    \n",
    "    label = to_label(keywords)\n",
    "        \n",
    "    processed_talks.append( (sentences_ted, label) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now all talks are given as a list of tokens, split into sentences, with their keywords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([['here', 'are', 'two', 'reasons', 'companies', 'fail', 'they', 'only', 'do', 'more', 'of', 'the', 'same', 'or', 'they', 'only', 'do', 'what', 's', 'new'], ['to', 'me', 'the', 'real', 'real', 'solution', 'to', 'quality', 'growth', 'is', 'figuring', 'out', 'the', 'balance', 'between', 'two', 'activities', 'exploration', 'and', 'exploitation'], ['both', 'are', 'necessary', 'but', 'it', 'can', 'be', 'too', 'much', 'of', 'a', 'good', 'thing'], ['consider', 'facit'], ['i', 'm', 'actually', 'old', 'enough', 'to', 'remember', 'them'], ['facit', 'was', 'a', 'fantastic', 'company'], ['they', 'were', 'born', 'deep', 'in', 'the', 'swedish', 'forest', 'and', 'they', 'made', 'the', 'best', 'mechanical', 'calculators', 'in', 'the', 'world'], ['everybody', 'used', 'them'], ['and', 'what', 'did', 'facit', 'do', 'when', 'the', 'electronic', 'calculator', 'came', 'along', 'they', 'continued', 'doing', 'exactly', 'the', 'same'], ['in', 'six', 'months', 'they', 'went', 'from', 'maximum', 'revenue'], ['and', 'they', 'were', 'gone'], ['gone'], ['to', 'me', 'the', 'irony', 'about', 'the', 'facit', 'story', 'is', 'hearing', 'about', 'the', 'facit', 'engineers', 'who', 'had', 'bought', 'cheap', 'small', 'electronic', 'calculators', 'in', 'japan', 'that', 'they', 'used', 'to', 'double', 'check', 'their', 'calculators'], ['facit', 'did', 'too', 'much', 'exploitation'], ['but', 'exploration', 'can', 'go', 'wild', 'too'], ['a', 'few', 'years', 'back', 'i', 'worked', 'closely', 'alongside', 'a', 'european', 'biotech', 'company'], ['let', 's', 'call', 'them', 'oncosearch'], ['the', 'company', 'was', 'brilliant'], ['they', 'had', 'applications', 'that', 'promised', 'to', 'diagnose', 'even', 'cure', 'certain', 'forms', 'of', 'blood', 'cancer'], ['every', 'day', 'was', 'about', 'creating', 'something', 'new'], ['they', 'were', 'extremely', 'innovative', 'and', 'the', 'mantra', 'was', 'when', 'we', 'only', 'get', 'it', 'right', 'or', 'even', 'we', 'want', 'it', 'perfect'], ['the', 'sad', 'thing', 'is', 'before', 'they', 'became', 'perfect', 'even', 'good', 'enough', 'they', 'became', 'obsolete'], ['oncosearch', 'did', 'too', 'much', 'exploration'], ['i', 'first', 'heard', 'about', 'exploration', 'and', 'exploitation', 'about', '15', 'years', 'ago', 'when', 'i', 'worked', 'as', 'a', 'visiting', 'scholar', 'at', 'stanford', 'university'], ['the', 'founder', 'of', 'the', 'idea', 'is', 'jim', 'march'], ['and', 'to', 'me', 'the', 'power', 'of', 'the', 'idea', 'is', 'its', 'practicality'], ['exploration'], ['exploration', 'is', 'about', 'coming', 'up', 'with', 'what', 's', 'new'], ['it', 's', 'about', 'search', 'it', 's', 'about', 'discovery', 'it', 's', 'about', 'new', 'products', 'it', 's', 'about', 'new', 'innovations'], ['it', 's', 'about', 'changing', 'our', 'frontiers'], ['our', 'heroes', 'are', 'people', 'who', 'have', 'done', 'exploration', 'madame', 'curie', 'picasso', 'neil', 'armstrong', 'sir', 'edmund', 'hillary', 'etc'], ['i', 'come', 'from', 'norway', 'all', 'our', 'heroes', 'are', 'explorers', 'and', 'they', 'deserve', 'to', 'be'], ['we', 'all', 'know', 'that', 'exploration', 'is', 'risky'], ['we', 'don', 't', 'know', 'the', 'answers', 'we', 'don', 't', 'know', 'if', 'we', 're', 'going', 'to', 'find', 'them', 'and', 'we', 'know', 'that', 'the', 'risks', 'are', 'high'], ['exploitation', 'is', 'the', 'opposite'], ['exploitation', 'is', 'taking', 'the', 'knowledge', 'we', 'have', 'and', 'making', 'good', 'better'], ['exploitation', 'is', 'about', 'making', 'our', 'trains', 'run', 'on', 'time'], ['it', 's', 'about', 'making', 'good', 'products', 'faster', 'and', 'cheaper'], ['exploitation', 'is', 'not', 'risky', 'in', 'the', 'short', 'term'], ['but', 'if', 'we', 'only', 'exploit', 'it', 's', 'very', 'risky', 'in', 'the', 'long', 'term'], ['and', 'i', 'think', 'we', 'all', 'have', 'memories', 'of', 'the', 'famous', 'pop', 'groups', 'who', 'keep', 'singing', 'the', 'same', 'songs', 'again', 'and', 'again', 'until', 'they', 'become', 'obsolete', 'or', 'even', 'pathetic'], ['that', 's', 'the', 'risk', 'of', 'exploitation'], ['so', 'if', 'we', 'take', 'a', 'long', 'term', 'perspective', 'we', 'explore'], ['if', 'we', 'take', 'a', 'short', 'term', 'perspective', 'we', 'exploit'], ['small', 'children', 'they', 'explore', 'all', 'day'], ['all', 'day', 'it', 's', 'about', 'exploration'], ['as', 'we', 'grow', 'older', 'we', 'explore', 'less', 'because', 'we', 'have', 'more', 'knowledge', 'to', 'exploit', 'on'], ['the', 'same', 'goes', 'for', 'companies'], ['companies', 'become', 'by', 'nature', 'less', 'innovative', 'as', 'they', 'become', 'more', 'competent'], ['and', 'this', 'is', 'of', 'course', 'a', 'big', 'worry', 'to', 'ceos'], ['and', 'i', 'hear', 'very', 'often', 'questions', 'phrased', 'in', 'different', 'ways'], ['for', 'example', 'how', 'can', 'i', 'both', 'effectively', 'run', 'and', 'reinvent', 'my', 'company', 'or', 'how', 'can', 'i', 'make', 'sure', 'that', 'our', 'company', 'changes', 'before', 'we', 'become', 'obsolete', 'or', 'are', 'hit', 'by', 'a', 'crisis', 'so', 'doing', 'one', 'well', 'is', 'difficult'], ['doing', 'both', 'well', 'as', 'the', 'same', 'time', 'is', 'art', 'pushing', 'both', 'exploration', 'and', 'exploitation'], ['so', 'one', 'thing', 'we', 've', 'found', 'is', 'only', 'about', 'two', 'percent', 'of', 'companies', 'are', 'able', 'to', 'effectively', 'explore', 'and', 'exploit', 'at', 'the', 'same', 'time', 'in', 'parallel'], ['but', 'when', 'they', 'do', 'the', 'payoffs', 'are', 'huge'], ['so', 'we', 'have', 'lots', 'of', 'great', 'examples'], ['we', 'have', 'nestl', 'creating', 'nespresso', 'we', 'have', 'lego', 'going', 'into', 'animated', 'films', 'toyota', 'creating', 'the', 'hybrids', 'unilever', 'pushing', 'into', 'sustainability', 'there', 'are', 'lots', 'of', 'examples', 'and', 'the', 'benefits', 'are', 'huge'], ['why', 'is', 'balancing', 'so', 'difficult', 'i', 'think', 'it', 's', 'difficult', 'because', 'there', 'are', 'so', 'many', 'traps', 'that', 'keep', 'us', 'where', 'we', 'are'], ['so', 'i', 'll', 'talk', 'about', 'two', 'but', 'there', 'are', 'many'], ['so', 'let', 's', 'talk', 'about', 'the', 'perpetual', 'search', 'trap'], ['we', 'discover', 'something', 'but', 'we', 'don', 't', 'have', 'the', 'patience', 'or', 'the', 'persistence', 'to', 'get', 'at', 'it', 'and', 'make', 'it', 'work'], ['so', 'instead', 'of', 'staying', 'with', 'it', 'we', 'create', 'something', 'new'], ['but', 'the', 'same', 'goes', 'for', 'that', 'then', 'we', 're', 'in', 'the', 'vicious', 'circle', 'of', 'actually', 'coming', 'up', 'with', 'ideas', 'but', 'being', 'frustrated'], ['oncosearch', 'was', 'a', 'good', 'example'], ['a', 'famous', 'example', 'is', 'of', 'course', 'xerox'], ['but', 'we', 'don', 't', 'only', 'see', 'this', 'in', 'companies'], ['we', 'see', 'this', 'in', 'the', 'public', 'sector', 'as', 'well'], ['we', 'all', 'know', 'that', 'any', 'kind', 'of', 'effective', 'reform', 'of', 'education', 'research', 'health', 'care', 'even', 'defense', 'takes', '10', '15', 'maybe', '20', 'years', 'to', 'work'], ['but', 'still', 'we', 'change', 'much', 'more', 'often'], ['we', 'really', 'don', 't', 'give', 'them', 'the', 'chance'], ['another', 'trap', 'is', 'the', 'success', 'trap'], ['facit', 'fell', 'into', 'the', 'success', 'trap'], ['they', 'literally', 'held', 'the', 'future', 'in', 'their', 'hands', 'but', 'they', 'couldn', 't', 'see', 'it'], ['they', 'were', 'simply', 'so', 'good', 'at', 'making', 'what', 'they', 'loved', 'doing', 'that', 'they', 'wouldn', 't', 'change'], ['we', 'are', 'like', 'that', 'too'], ['when', 'we', 'know', 'something', 'well', 'it', 's', 'difficult', 'to', 'change'], ['bill', 'gates', 'has', 'said', 'success', 'is', 'a', 'lousy', 'teacher'], ['it', 'seduces', 'us', 'into', 'thinking', 'we', 'cannot', 'fail'], ['that', 's', 'the', 'challenge', 'with', 'success'], ['so', 'i', 'think', 'there', 'are', 'some', 'lessons', 'and', 'i', 'think', 'they', 'apply', 'to', 'us'], ['and', 'they', 'apply', 'to', 'our', 'companies'], ['the', 'first', 'lesson', 'is', 'get', 'ahead', 'of', 'the', 'crisis'], ['and', 'any', 'company', 'that', 's', 'able', 'to', 'innovate', 'is', 'actually', 'able', 'to', 'also', 'buy', 'an', 'insurance', 'in', 'the', 'future'], ['netflix', 'they', 'could', 'so', 'easily', 'have', 'been', 'content', 'with', 'earlier', 'generations', 'of', 'distribution', 'but', 'they', 'always', 'and', 'i', 'think', 'they', 'will', 'always', 'keep', 'pushing', 'for', 'the', 'next', 'battle'], ['i', 'see', 'other', 'companies', 'that', 'say', 'i', 'll', 'win', 'the', 'next', 'innovation', 'cycle', 'whatever', 'it', 'takes'], [], ['think', 'in', 'multiple', 'time', 'scales'], ['i', 'll', 'share', 'a', 'chart', 'with', 'you', 'and', 'i', 'think', 'it', 's', 'a', 'wonderful', 'one'], ['any', 'company', 'we', 'look', 'at', 'taking', 'a', 'one', 'year', 'perspective', 'and', 'looking', 'at', 'the', 'valuation', 'of', 'the', 'company', 'innovation', 'typically', 'accounts', 'for', 'only', 'about', '30', 'percent'], ['so', 'when', 'we', 'think', 'one', 'year', 'innovation', 'isn', 't', 'really', 'that', 'important'], ['move', 'ahead', 'take', 'a', '10', 'year', 'perspective', 'on', 'the', 'same', 'company', 'suddenly', 'innovation', 'and', 'ability', 'to', 'renew', 'account', 'for', '70', 'percent'], ['but', 'companies', 'can', 't', 'choose'], ['they', 'need', 'to', 'fund', 'the', 'journey', 'and', 'lead', 'the', 'long', 'term'], ['invite', 'talent'], ['i', 'don', 't', 'think', 'it', 's', 'possible', 'for', 'any', 'of', 'us', 'to', 'be', 'able', 'to', 'balance', 'exploration', 'and', 'exploitation', 'by', 'ourselves'], ['i', 'think', 'it', 's', 'a', 'team', 'sport'], ['i', 'think', 'we', 'need', 'to', 'allow', 'challenging'], ['i', 'think', 'the', 'mark', 'of', 'a', 'great', 'company', 'is', 'being', 'open', 'to', 'be', 'challenged', 'and', 'the', 'mark', 'of', 'a', 'good', 'corporate', 'board', 'is', 'to', 'constructively', 'challenge'], ['i', 'think', 'that', 's', 'also', 'what', 'good', 'parenting', 'is', 'about'], ['be', 'skeptical', 'of', 'success'], ['maybe', 'it', 's', 'useful', 'to', 'think', 'back', 'at', 'the', 'old', 'triumph', 'marches', 'in', 'rome', 'when', 'the', 'generals', 'after', 'a', 'big', 'victory', 'were', 'given', 'their', 'celebration'], ['riding', 'into', 'rome', 'on', 'the', 'carriage', 'they', 'always', 'had', 'a', 'companion', 'whispering', 'in', 'their', 'ear', 'remember', 'you', 're', 'only', 'human'], [], ['so', 'i', 'hope', 'i', 'made', 'the', 'point', 'balancing', 'exploration', 'and', 'exploitation', 'has', 'a', 'huge', 'payoff'], ['but', 'it', 's', 'difficult', 'and', 'we', 'need', 'to', 'be', 'conscious'], ['i', 'want', 'to', 'just', 'point', 'out', 'two', 'questions', 'that', 'i', 'think', 'are', 'useful'], ['first', 'question', 'is', 'looking', 'at', 'your', 'own', 'company', 'in', 'which', 'areas', 'do', 'you', 'see', 'that', 'the', 'company', 'is', 'at', 'the', 'risk', 'of', 'falling', 'into', 'success', 'traps', 'of', 'just', 'going', 'on', 'autopilot', 'and', 'what', 'can', 'you', 'do', 'to', 'challenge'], ['when', 'did', 'i', 'explore', 'something', 'new', 'last', 'and', 'what', 'kind', 'of', 'effect', 'did', 'it', 'have', 'on', 'me', 'is', 'that', 'something', 'i', 'should', 'do', 'more', 'of', 'in', 'my', 'case', 'yes'], ['so', 'let', 'me', 'leave', 'you', 'with', 'this'], ['whether', 'you', 're', 'an', 'explorer', 'by', 'nature', 'or', 'whether', 'you', 'tend', 'to', 'exploit', 'what', 'you', 'already', 'know', 'don', 't', 'forget', 'the', 'beauty', 'is', 'in', 'the', 'balance'], ['thank', 'you']], 'ooo')\n"
     ]
    }
   ],
   "source": [
    "print(processed_talks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ooo\n",
      "ooo\n",
      "ooo\n",
      "ooD\n",
      "ToD\n",
      "ooo\n",
      "ooo\n",
      "ooo\n",
      "ooo\n",
      "ToD\n",
      "ooo\n",
      "ooD\n",
      "oEo\n",
      "ToD\n",
      "ooo\n",
      "ooo\n",
      "ooD\n",
      "ooo\n",
      "ToD\n",
      "ooo\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,20):\n",
    "    print ((processed_talks[i])[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Randomly permute the dataset, and keep the last two blocks of 250 for validation and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1585 training items\n",
      "250 testing items\n",
      "250 validation items\n"
     ]
    }
   ],
   "source": [
    "shuffle(processed_talks)\n",
    "\n",
    "data_training = processed_talks[:-500]\n",
    "print( str(len(data_training)) + \" training items\")  \n",
    "data_testing = processed_talks[-500:-250]\n",
    "print( str(len(data_testing)) + \" testing items\") \n",
    "data_validation = processed_talks[-250:]\n",
    "print( str(len(data_validation)) + \" validation items\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Compare the learning curves of the model starting from random embeddings, starting from GloVe embeddings (http://nlp.stanford.edu/data/glove.6B.zip; 50 dimensions) or fixed to be the GloVe values. Training in batches is more stable (e.g. 50), which model works best on training vs. test? Which model works best on held-out accuracy?\n",
    "2. What happens if you try alternative non-linearities (logistic sigmoid or ReLU instead of tanh)?\n",
    "3. What happens if you add dropout to the network?\n",
    "4. What happens if you vary the size of the hidden layer?\n",
    "5. How would the code change if you wanted to add a second hidden layer?\n",
    "6. How does the training algorithm affect the quality of the model?\n",
    "7. Project the embeddings of the labels onto 2 dimensions and visualise (each row of the projection matrix V corresponds a label embedding). Do you see anything interesting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#https://www.tensorflow.org/tutorials/word2vec \n",
    "\n",
    "#We need to find the embedding size, this can be either retrieved from the glove dataset or by taking our embedding size as\n",
    "#the size of our largest sentence\n",
    "\n",
    "#practical 1 learnt embeddings by using the Word2Vec(sentences, size=100, min_count=10)\n",
    "#Not sure if this should still be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import math\n",
    "vocabulary_size = 4\n",
    "embedding_size = 4\n",
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#We should vary our use of how we initialise embeddings\n",
    "#1.random embeddings\n",
    "embeddings = tf.Variable(\n",
    "    tf.random_uniform([vocabulary_size, embedding_size], -1.0, 1.0))\n",
    "\n",
    "#2. start from GloVe\n",
    "\n",
    "#3. fixed as GloVe\n",
    "\n",
    "nce_weights = tf.Variable(\n",
    "  tf.truncated_normal([vocabulary_size, embedding_size],\n",
    "                      stddev=1.0 / math.sqrt(embedding_size)))\n",
    "\n",
    "nce_biases = tf.Variable(tf.zeros([vocabulary_size]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "train_inputs = tf.placeholder(tf.int32, shape=[batch_size])\n",
    "train_labels = tf.placeholder(tf.int32, shape=[batch_size, 1])\n",
    "embed = tf.nn.embedding_lookup(embeddings, train_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Adjust non-linearirities\n",
    "\n",
    "#Adjust dropout\n",
    "\n",
    "#Adjust hidden layer size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'num_sampled' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-26e8d866c124>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m loss = tf.reduce_mean(\n\u001b[1;32m      3\u001b[0m   tf.nn.nce_loss(nce_weights, nce_biases, embed, train_labels,\n\u001b[0;32m----> 4\u001b[0;31m                  num_sampled, vocabulary_size))\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'num_sampled' is not defined"
     ]
    }
   ],
   "source": [
    "#What is our loss function, hint not this\n",
    "loss = tf.reduce_mean(\n",
    "  tf.nn.nce_loss(nce_weights, nce_biases, embed, train_labels,\n",
    "                 num_sampled, vocabulary_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#We should use Adam as optimiser\n",
    "optimizer = tf.train.AdamOptimizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Code to add second hidden layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#tSNE visualisation"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
